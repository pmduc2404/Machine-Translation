{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import models\n",
    "import torch\n",
    "import data_reader\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from string import punctuation\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vie = data_reader.read_text(\"./eng_vie/vi_sents\")\n",
    "data_eng = data_reader.read_text(\"./eng_vie/en_sents\")\n",
    "\n",
    "sents_vie = data_reader.to_lines(data_vie)\n",
    "sents_eng = data_reader.to_lines(data_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame({'sents_eng': sents_eng, 'sents_vie': sents_vie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, lowercase=False, remove_punc=False, remove_num=False, sos_token='<sos>', eos_token='<eos>'):\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    if remove_punc:\n",
    "        text = ''.join([ch for ch in text if ch not in punctuation])\n",
    "    if remove_num:\n",
    "        text = ''.join([ch for ch in text if ch not in '1234567890'])\n",
    "    text = [sos_token] + word_tokenize(text) + [eos_token]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_eng'] = dataset['sents_eng'].apply(lambda x: clean_text(x, lowercase=True, remove_punc=True, remove_num=False))\n",
    "dataset['clean_vie'] = dataset['sents_vie'].apply(lambda x: clean_text(x, lowercase=True, remove_punc=True, remove_num=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_token = '<unk>'\n",
    "pad_token = '<pad>'\n",
    "sos_token = '<sos>'\n",
    "eos_token = '<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "specials = [unk_token, pad_token, sos_token, eos_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = build_vocab_from_iterator(dataset['clean_eng'], specials = specials)\n",
    "vie_vocab = build_vocab_from_iterator(dataset['clean_vie'], specials = specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_number(text, vocab):\n",
    "    return vocab.lookup_indices(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['eng_nums'] = dataset['clean_eng'].apply(lambda x: text_to_number(x, eng_vocab))\n",
    "dataset['vie_nums'] = dataset['clean_vie'].apply(lambda x: text_to_number(x, vie_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(dataset, test_size = 0.2):\n",
    "    train, test = train_test_split(dataset, test_size=test_size, random_state = 42)\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = eng_vocab[pad_token]\n",
    "unk_index = eng_vocab[unk_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vie_vocab.set_default_index(unk_index)\n",
    "eng_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(eng_vocab)\n",
    "TGT_VOCAB_SIZE = len(vie_vocab)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "best_model = models.EngToVieTranslation(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " best_model.load_state_dict(torch.load(\"best_translate_model.pth\", map_location=device))\n",
    " best_model = best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, eng_sent, eng_vocab, vie_vocab, device, max_length=50):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    eng_sent = eng_vocab.lookup_indices([sos_token] + word_tokenize(eng_sent.lower()) + [eos_token])\n",
    "    eng_sent = torch.tensor(eng_sent).unsqueeze(1).to(device)\n",
    "    \n",
    "    answer = torch.tensor([[vie_vocab[sos_token]]]).to(device)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(eng_sent, answer)\n",
    "            output = model(eng_sent, answer, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n",
    "            \n",
    "            output = output[-1].argmax().item()\n",
    "            answer = torch.cat([answer, torch.tensor([[output]], device = device)], dim = 0)\n",
    "            if output == eng_vocab[eos_token]:\n",
    "                break\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_sents = test[0:10][['sents_eng', 'sents_vie']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == pad_index).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == pad_index).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eng: I lost my camera the other day.\n",
      "Vie: tôi đã mất máy ảnh của tôi vào ngày khác.\n",
      "Translated: <sos> tôi bị mất máy ảnh vào ngày khác <eos>\n",
      "\n",
      "\n",
      "Eng: I'm not very good with children.\n",
      "Vie: Tôi không tốt với trẻ em.\n",
      "Translated: <sos> tôi rất giỏi vì con cái nhìn không phải bằng cách <eos>\n",
      "\n",
      "\n",
      "Eng: Don't you worry about that?\n",
      "Vie: bạn không lo lắng về điều đó?\n",
      "Translated: <sos> bạn lo lắng về điều đó phải làm gì <eos>\n",
      "\n",
      "\n",
      "Eng: He did his best to the end\n",
      "Vie: anh ấy đã làm hết sức mình đến cuối cùng\n",
      "Translated: <sos> anh ấy đã làm hết sức mình đến cuối cùng <eos>\n",
      "\n",
      "\n",
      "Eng: Tom, I'm in trouble. I need you to come get me.\n",
      "Vie: tom, tôi đang gặp rắc rối tôi cần bạn đến để có được tôi\n",
      "Translated: <sos> tôi cần quay lại để khiến bạn ngắt tôi gặp rắc rối <eos>\n",
      "\n",
      "\n",
      "Eng: I'm just going to run down to buy some tickets.\n",
      "Vie: Tôi sẽ chạy xuống để mua vé.\n",
      "Translated: <sos> tôi chỉ muốn mua một số vé để làm phiền <eos>\n",
      "\n",
      "\n",
      "Eng: What more could I want?\n",
      "Vie: tôi muốn gì hơn nữa\n",
      "Translated: <sos> tôi có thể muốn gì hơn nữa <eos>\n",
      "\n",
      "\n",
      "Eng: Tom didn't say anything about that to me\n",
      "Vie: tom không nói gì với tôi\n",
      "Translated: <sos> tom nói gì về tôi làm điều đó <eos>\n",
      "\n",
      "\n",
      "Eng: The summit of the mountain is covered with fresh snow\n",
      "Vie: đỉnh núi phủ đầy tuyết trắng\n",
      "Translated: <sos> đỉnh núi với đỉnh núi dốc của tuyết <eos>\n",
      "\n",
      "\n",
      "Eng: How many times have you been to Europe?\n",
      "Vie: bạn đã đến châu âu bao nhiêu lần rồi\n",
      "Translated: <sos> bạn đã đến châu âu bao nhiêu lần rồi <eos>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eng_sent, vie_sent in eng_sents:\n",
    "    translated = translate(best_model, eng_sent, eng_vocab, vie_vocab, device)\n",
    "    translated = ' '.join([vie_vocab.get_itos()[i] for i in translated])\n",
    "    print(f\"Eng: {eng_sent}\")\n",
    "    print(f\"Vie: {vie_sent}\")\n",
    "    print(f\"Translated: {translated}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate BLEU score\n",
    "def calculate_bleu_score(model, data, eng_vocab, vie_vocab, device):\n",
    "    translated_corpus = []\n",
    "    reference_corpus = []\n",
    "    for eng_sent, vie_sent in data[['sents_eng', 'sents_vie']].values:\n",
    "        translated = translate(model, eng_sent, eng_vocab, vie_vocab, device)\n",
    "        translated = [vie_vocab.get_itos()[i] for i in translated]\n",
    "        translated_corpus.append(translated[1:-1])\n",
    "        reference_corpus.append([word_tokenize(vie_sent.lower())])\n",
    "        \n",
    "    return corpus_bleu(reference_corpus, translated_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3393429640302753"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu_score(best_model, test, eng_vocab, vie_vocab, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
